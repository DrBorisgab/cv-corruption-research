{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\diploma\\cv-corruption-research\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#! pip install albumentations==0.4.6\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import segmentation_models_pytorch as smp\n",
    "from typing import Final\n",
    "import os\n",
    "from torchvision import transforms as T\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import rasterio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "architectures: Final[dict] = {'Unet': smp.Unet,\n",
    "                              'Unet++': smp.UnetPlusPlus,\n",
    "                              'MAnet': smp.MAnet,\n",
    "                              'DeepLabV3+': smp.DeepLabV3Plus}\n",
    "\n",
    "encoders: Final[dict] = {'mit-b2': 'mit_b2',\n",
    "                         'mit-b3': 'mit_b3',\n",
    "                         'efficientnet-b1': 'efficientnet-b1',\n",
    "                         'efficientnet-b2': 'efficientnet-b2',\n",
    "                         'efficientnet-b3': 'efficientnet-b3',\n",
    "                         'efficientnet-b4': 'efficientnet-b4',\n",
    "                         'efficientnet-b5': 'efficientnet-b5',\n",
    "                         'timm-res2net50-26w-4s': 'timm-res2net50_26w_4s'}\n",
    "\n",
    "models_root = 'D:\\diploma\\cv-corruption-research\\models'\n",
    "model_names = ['DeepLabV3+_efficientnet-b4' , 'MAnet_efficientnet-b4', 'Unet_mit-b2', 'Unet++_efficientnet-b5']\n",
    "\n",
    "model_name = model_names[0]\n",
    "\n",
    "segm_arch = model_name.split('_')[0]\n",
    "encoder = model_name.split('_')[1]\n",
    "\n",
    "model = architectures[segm_arch](in_channels = 3, classes=4, \n",
    "                                 encoder_name = encoders[encoder],\n",
    "                                 encoder_weights=None,\n",
    "                                 activation = None).to('cuda')\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(models_root, f'{model_name}.pth')))\n",
    "model.eval();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normparams= {'mean': [105.  , 109.,  100.], 'std': [53.660343, 51.114082, 51.887432]}\n",
    "\n",
    "def get_img_transform(normparams):\n",
    "    return T.Compose([T.Lambda(lambda x: torch.as_tensor(x, dtype=torch.float)),\n",
    "                      T.Normalize(**normparams)])\n",
    "\n",
    "\n",
    "def get_mask_inverse_transform():\n",
    "    def transform(x):\n",
    "        x = x.detach().cpu().numpy()\n",
    "        return x\n",
    "    return transform\n",
    "\n",
    "\n",
    "def get_predictor(model,\n",
    "                  transform,\n",
    "                  inv_transform,\n",
    "                  device: str = 'cpu'):\n",
    "    def predictor(sample):\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        with torch.no_grad():\n",
    "            return inv_transform(model(torch.unsqueeze(transform(sample), 0).to(device))[0])\n",
    "    return predictor\n",
    "\n",
    "sample_size=(1024,1024)\n",
    "\n",
    "def add_border(img):\n",
    "        img = to_tensor(img)\n",
    "\n",
    "        old_size = (img.shape[1], img.shape[2])\n",
    "\n",
    "        new_size = ((int(old_size[0] / sample_size[0]) + 1)*sample_size[0], \n",
    "                    (int(old_size[1] / sample_size[1]) + 1)*sample_size[1])\n",
    "            \n",
    "        new_img = torch.zeros((img.shape[0], new_size[0], new_size[1]))\n",
    "        \n",
    "        add_x = [int((new_size[0]-old_size[0])/2), int((new_size[0]-old_size[0])/2)]\n",
    "        add_y = [int((new_size[1]-old_size[1])/2), int((new_size[1]-old_size[1])/2)]\n",
    "\n",
    "        if new_size[0]-np.sum(add_x) != img.shape[1]:\n",
    "            add_x[1] = add_x[1] + 1\n",
    "\n",
    "        if new_size[1]-np.sum(add_y) != img.shape[2]:\n",
    "            add_y[1] = add_y[1] + 1\n",
    "\n",
    "        new_img[:, add_x[0]:new_size[0]-add_x[1], \n",
    "                   add_y[0]:new_size[1]-add_y[1]] = img\n",
    "\n",
    "        return new_img.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "predictor = get_predictor(model,\n",
    "                          transform=get_img_transform(normparams),\n",
    "                          inv_transform=get_mask_inverse_transform(),\n",
    "                          device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = rasterio.open(\"true_images/1.tif\")\n",
    "sample = image.read().swapaxes(0,2).swapaxes(0,1)\n",
    "#sample = sample[:992,:944,:] # можем обрезать до ближайшего кратного числа\n",
    "mask = predictor(add_border(sample)) #returns mask with raw logits, shape = (4, H, W)\n",
    "fig, axes= plt.subplots(1,2)\n",
    "axes[0].imshow(torch.from_numpy(sample))\n",
    "axes[1].imshow(torch.from_numpy(mask)[3,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_num = 14\n",
    "\n",
    "for i in range(pic_num):\n",
    "    image = rasterio.open(\"true_images/\"+ str(i+1) +\".tif\")\n",
    "    image = image.read().swapaxes(0,2).swapaxes(0,1)/255\n",
    "    \n",
    "    mask = predictor(add_border(image)) #returns mask with raw logits, shape = (4, H, W)\n",
    "    fig, axes= plt.subplots(1,2)\n",
    "\n",
    "    axes[0].imshow(torch.from_numpy(image))\n",
    "    axes[1].imshow(torch.from_numpy(mask)[3,:,:])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
