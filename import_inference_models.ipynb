{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import segmentation_models_pytorch as smp\n",
    "from typing import Final\n",
    "import os\n",
    "from torchvision import transforms as T\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import rasterio\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from segmentation_models_pytorch.utils.metrics import IoU\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "architectures: Final[dict] = {'Unet': smp.Unet,\n",
    "                              'Unet++': smp.UnetPlusPlus,\n",
    "                              'MAnet': smp.MAnet,\n",
    "                              'DeepLabV3+': smp.DeepLabV3Plus}\n",
    "\n",
    "encoders: Final[dict] = {'mit-b2': 'mit_b2',\n",
    "                         'mit-b3': 'mit_b3',\n",
    "                         'efficientnet-b1': 'efficientnet-b1',\n",
    "                         'efficientnet-b2': 'efficientnet-b2',\n",
    "                         'efficientnet-b3': 'efficientnet-b3',\n",
    "                         'efficientnet-b4': 'efficientnet-b4',\n",
    "                         'efficientnet-b5': 'efficientnet-b5',\n",
    "                         'timm-res2net50-26w-4s': 'timm-res2net50_26w_4s'}\n",
    "\n",
    "models_root = 'D:\\diploma\\cv-corruption-research\\models'\n",
    "model_names = ['DeepLabV3+_efficientnet-b4' , 'MAnet_efficientnet-b4', 'Unet_mit-b2', 'Unet++_efficientnet-b5']\n",
    "\n",
    "model_name = model_names[3]\n",
    "\n",
    "segm_arch = model_name.split('_')[0]\n",
    "encoder = model_name.split('_')[1]\n",
    "\n",
    "model = architectures[segm_arch](in_channels = 3, classes=4, \n",
    "                                 encoder_name = encoders[encoder],\n",
    "                                 encoder_weights=None,\n",
    "                                 activation = None).to('cuda')\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(models_root, f'{model_name}.pth')))\n",
    "model.eval();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "normparams= {'mean': [105.  , 109.,  100.], 'std': [53.660343, 51.114082, 51.887432]}\n",
    "\n",
    "def get_img_transform(normparams):\n",
    "    return T.Compose([T.Lambda(lambda x: torch.as_tensor(x, dtype=torch.float)),\n",
    "                      T.Normalize(**normparams)])\n",
    "\n",
    "\n",
    "def get_mask_inverse_transform():\n",
    "    def transform(x):\n",
    "        x = x.detach().cpu().numpy()\n",
    "        return x\n",
    "    return transform\n",
    "\n",
    "\n",
    "def get_predictor(model,\n",
    "                  transform,\n",
    "                  inv_transform,\n",
    "                  device: str = 'cpu'):\n",
    "    def predictor(sample):\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        with torch.no_grad():\n",
    "            return inv_transform(model(torch.unsqueeze(transform(sample), 0).to(device))[0])\n",
    "    return predictor\n",
    "\n",
    "sample_size=(1024,1024)\n",
    "\n",
    "def add_border(img):\n",
    "        img = to_tensor(img)\n",
    "\n",
    "        old_size = (img.shape[1], img.shape[2])\n",
    "\n",
    "        new_size = ((int(old_size[0] / sample_size[0]) + 1)*sample_size[0], \n",
    "                    (int(old_size[1] / sample_size[1]) + 1)*sample_size[1])\n",
    "            \n",
    "        new_img = torch.zeros((img.shape[0], new_size[0], new_size[1]))\n",
    "        \n",
    "        add_x = [int((new_size[0]-old_size[0])/2), int((new_size[0]-old_size[0])/2)]\n",
    "        add_y = [int((new_size[1]-old_size[1])/2), int((new_size[1]-old_size[1])/2)]\n",
    "\n",
    "        if new_size[0]-np.sum(add_x) != img.shape[1]:\n",
    "            add_x[1] = add_x[1] + 1\n",
    "\n",
    "        if new_size[1]-np.sum(add_y) != img.shape[2]:\n",
    "            add_y[1] = add_y[1] + 1\n",
    "\n",
    "        new_img[:, add_x[0]:new_size[0]-add_x[1], \n",
    "                   add_y[0]:new_size[1]-add_y[1]] = img\n",
    "\n",
    "        return new_img.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "predictor = get_predictor(model,\n",
    "                          transform=get_img_transform(normparams),\n",
    "                          inv_transform=get_mask_inverse_transform(),\n",
    "                          device='cuda')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Cropp images for GPU optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\diploma\\cv-corruption-research\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4465620995949126 0.6928671612478626 0.3873576126052838 0.3459532115301117\n"
     ]
    }
   ],
   "source": [
    "pic_num = 13\n",
    "IoU_res, p, r, f1 = [],[],[],[]\n",
    "\n",
    "for i in range(pic_num):\n",
    "    image = rasterio.open(\"true_images/\"+ str(i+1) +\".tif\")\n",
    "    true_mask = rasterio.open(\"true_rastr_masks/\"+ str(i+1) +\".tif\")\n",
    "\n",
    "    # cropp images for GPU optimization\n",
    "    x = image.read()\n",
    "    x = torch.tensor(x)\n",
    "    kernel_size, stride = 1024, 1024\n",
    "    patches = x.unfold(1, kernel_size, stride).unfold(2, kernel_size, stride)\n",
    "    patches = patches.contiguous().view(patches.size(0), -1, kernel_size, kernel_size)\n",
    "    patches = patches.swapaxes(0,1).swapaxes(1,3)\n",
    "    \n",
    "     # cropp mask for GPU optimization\n",
    "    true_mask = true_mask.read()\n",
    "    true_mask = torch.tensor(true_mask)\n",
    "    kernel_size, stride = 1024, 1024\n",
    "    mask_patches = true_mask.unfold(1, kernel_size, stride).unfold(2, kernel_size, stride)\n",
    "    mask_patches = mask_patches.contiguous().view(mask_patches.size(0), -1, kernel_size, kernel_size)\n",
    "    mask_patches = mask_patches.swapaxes(0,1).swapaxes(1,3)\n",
    "    val_idx = []\n",
    "\n",
    "    # drop pics with no buildings\n",
    "    for i in range(len(mask_patches)):\n",
    "        if mask_patches[i].sum() != 0:\n",
    "            val_idx.append(i)\n",
    "    \n",
    "    for j in val_idx:\n",
    "        \n",
    "        image = patches[j].swapaxes(0,2).swapaxes(1,2)\n",
    "        true_mask = mask_patches[j]\n",
    "\n",
    "        mask = predictor(image) #returns mask with raw logits, shape = (4, H, W)\n",
    "\n",
    "        mask = torch.argmax(torch.from_numpy(mask), dim=0)\n",
    "        mask = mask == 3\n",
    "\n",
    "        true_mask = true_mask[:,:,0]\n",
    "\n",
    "        '''\n",
    "        fig, axes= plt.subplots(1,3)\n",
    "        axes[0].imshow(image.swapaxes(0,1).swapaxes(1,2))\n",
    "        axes[1].imshow(true_mask)\n",
    "        axes[2].imshow(mask)\n",
    "\n",
    "        axes[0].set_title('Image')\n",
    "        axes[1].set_title('True mask')\n",
    "        axes[2].set_title('Predict mask')\n",
    "        plt.show()\n",
    "        '''\n",
    "        \n",
    "        iou = IoU()\n",
    "        IoU_ = iou(mask,true_mask).item()\n",
    "        \n",
    "        true_mask, mask = true_mask.numpy().flatten(), mask.flatten()\n",
    "        precision = precision_score(true_mask, mask)\n",
    "        recall = recall_score(true_mask, mask)\n",
    "        f1_ = f1_score(true_mask, mask)\n",
    "        \n",
    "        p.append(precision)\n",
    "        r.append(recall)\n",
    "        f1.append(f1_)\n",
    "        IoU_res.append(IoU_)\n",
    "\n",
    "        #print(f1_,precision,recall,IoU_)\n",
    "    \n",
    "print(np.mean(f1), np.mean(p), np.mean(r), np.mean(IoU_res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
