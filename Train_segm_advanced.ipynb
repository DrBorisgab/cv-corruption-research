{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4579a8cc-95b3-4400-be6e-21e2106aa6b3",
   "metadata": {},
   "source": [
    "# Advanced training\n",
    "with augmentations, lr scheduling, testing on benchmarks and wandb logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd06ef71-05ab-4d88-9de1-b6fbebe24ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\diploma\\cv-corruption-research\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch # 1.8\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm.auto import tqdm\n",
    "import albumentations as A\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "#from dlutils.utils import visualization\n",
    "from dlutils.utils.utils import listdir\n",
    "from dlutils.learn import traintest, metrics, predict, losses\n",
    "from dlutils.learn.transforms import transforms, pipeline, augmentations, maskutils, postprocessors\n",
    "from dlutils.learn.datasets import from_npfiles\n",
    "from dlutils.utils.samplers.randomgridsampler import make_random_grid_sampler\n",
    "from dlutils.dataadapters.npfileadapter import NpFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a3ef9b-9a68-4dcb-9f34-fd03a8259817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "russia_manual_root = 'samples/'\n",
    "np_file_name = '/img_mask.np'\n",
    "# russia_pseudo_root = 'data/russia_pseudo/'\n",
    "\n",
    "# get lists of files in each directory\n",
    "russia_manual = os.listdir(russia_manual_root)\n",
    "russia_manual = [russia_manual_root+file+np_file_name for file in russia_manual]\n",
    "#russia_pseudo = os.listdir(russia_pseudo_root)\n",
    "#russia_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1c9d4ab-c11c-42b9-9c77-45e64df7b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "batch_size = 10\n",
    "normparams = transforms.get_normparams({'mean': (106.94118, 108.923965, 98.418015),\n",
    "                                        'std': (54.646156, 51.051823, 50.47959)}, 3)\n",
    "sample_size=512\n",
    "\n",
    "aug_dict = {\n",
    "            'Rotate':{'p':0.6},\n",
    "            'CenterCrop':{'height': sample_size, 'width':sample_size, 'p': 1., 'always_apply': True},\n",
    "            'RandomRotate90':{'p':0.5},\n",
    "            'Flip':{'p':0.5},\n",
    "            'RandomResizedCrop':{'height': sample_size, 'width':sample_size, 'scale':(0.8, 1.2), 'ratio':(1., 1.), 'p':0.2},\n",
    "            'ColorJitter':{'brightness':0.2, 'contrast':0.2, 'saturation':0.2, 'hue':0.1, 'p':0.2},\n",
    "            #'ChannelShuffle':{'p':0.1},\n",
    "            'Downscale':{'p':0.1},\n",
    "            'GridDistortion':{'p':0.2},\n",
    "            'ISONoise':{'p':0.2},\n",
    "            'ImageCompression':{'p':0.2},\n",
    "            #'GaussNoise':{'p':0.2},\n",
    "            'Emboss':{'p':0.2},\n",
    "            'Sharpen':{'p':0.2},\n",
    "            'Blur':{'p':0.1},\n",
    "            'CLAHE':{'p':0.2},\n",
    "            #'HistogramMatching':{'reference_images':reference, 'read_fn':lambda x: x, 'p':0.2, 'blend_ratio': (0.1, 0.9)},\n",
    "            #'PixelDistributionAdaptation':{'reference_images':reference, 'read_fn':lambda x: x, 'p':0.2, 'blend_ratio': (0.1, 0.7)}\n",
    "           }\n",
    "\n",
    "loss_str = \"smp.losses.JaccardLoss(mode='multiclass', from_logits=True)\"\n",
    "loss_fn = eval(loss_str)\n",
    "\n",
    "val_preprocess = transforms.get_transform_to_tensor(normparams)\n",
    "val_postprocess = pipeline.get_pipeline([transforms.get_transform_from_tensor(),\n",
    "                                                 maskutils.get_onehot_to_labels(),\n",
    "                                                 maskutils.clip_to_8bit])\n",
    "\n",
    "mixed_precision = True\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8dd5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = 'smp.Unet(encoder_name=\"resnet34\", encoder_weights=\"imagenet\")'\n",
    "model = eval(model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb4a254-df72-4391-a181-f8ee32baeed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['samples/001/img_mask.np', 'samples/002/img_mask.np', 'samples/003/img_mask.np', 'samples/004/img_mask.np', 'samples/005/img_mask.np', 'samples/006/img_mask.np', 'samples/008/img_mask.np', 'samples/009/img_mask.np', 'samples/010/img_mask.np', 'samples/011/img_mask.np', 'samples/012/img_mask.np', 'samples/013/img_mask.np', 'samples/014/img_mask.np', 'samples/015/img_mask.np', 'samples/016/img_mask.np', 'samples/017/img_mask.np', 'samples/018/img_mask.np', 'samples/019/img_mask.np', 'samples/020/img_mask.np', 'samples/021/img_mask.np', 'samples/022/img_mask.np', 'samples/023/img_mask.np', 'samples/024/img_mask.np', 'samples/027/img_mask.np', 'samples/028/img_mask.np', 'samples/029/img_mask.np', 'samples/030/img_mask.np', 'samples/031/img_mask.np', 'samples/033/img_mask.np', 'samples/034/img_mask.np', 'samples/038/img_mask.np', 'samples/039/img_mask.np', 'samples/040/img_mask.np', 'samples/041/img_mask.np', 'samples/042/img_mask.np', 'samples/043/img_mask.np', 'samples/044/img_mask.np', 'samples/046/img_mask.np', 'samples/048/img_mask.np', 'samples/050/img_mask.np', 'samples/051/img_mask.np']\n",
      "(41, 2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\diploma\\cv-corruption-research\\venv\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1692: UserWarning: Using default interpolation INTER_NEAREST, which is sub-optimal.Please specify interpolation mode for downscale and upscale explicitly.For additional information see this PR https://github.com/albumentations-team/albumentations/pull/584\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_files_str = 'russia_manual'\n",
    "train_weights_str = \"'auto'\"\n",
    "\n",
    "train_weights = eval(train_weights_str)\n",
    "train_files = eval(train_files_str)\n",
    "print(train_files)\n",
    "\n",
    "# ?\n",
    "# true_mask = true_mask.read()\n",
    "# true_mask = torch.tensor(true_mask)\n",
    "\n",
    "train_data = from_npfiles(train_files,\n",
    "                          sample_size=int(sample_size*1.5),\n",
    "                          pipeline=pipeline.get_pipeline([pipeline.get_img_mask_split(mask_channels=(3,)),\n",
    "                                                          augmentations.compose_from_dict(aug_dict),\n",
    "                                                          pipeline.get_dict_wrapper({'image': transforms.get_transform_to_tensor(normparams),\n",
    "                                                                                     'mask': transforms.get_transform_to_tensor(dtype=torch.int64)})]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_sampler=make_random_grid_sampler(train_data,\n",
    "                                                                                  batch_size=batch_size, \n",
    "                                                                                  length=2000,\n",
    "                                                                                  weights=train_weights\n",
    "                                                                                 ),\n",
    "                                           num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eff8a237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "epochs = 20 #40\n",
    "pbar = tqdm(total=traintest.infer_train_length(train_loader, epochs))\n",
    "lr = 5e-5\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "schedulers = traintest.make_schedulers(optimizer,\n",
    "                                       warmup_params ={'start_factor': 0.4,  'total_iters': 3},\n",
    "                                       exp_params = {'gamma': 0.98})\n",
    "\n",
    "\n",
    "wandb.init(project='swrc',\n",
    "           config={\"model\": model_str,\n",
    "                   #'params': total_params, \n",
    "                   'lr':lr, \n",
    "                   'batch_size': batch_size,\n",
    "                   'sample_size': sample_size,\n",
    "                   'aug': str(aug_dict),\n",
    "                   'data': train_files_str,\n",
    "                   'mixed_precision': mixed_precision,\n",
    "                   'train_weights': train_weights_str,\n",
    "                   'loss': loss_str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f04a07dd-4142-4ae1-84d8-28547a6745c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_io.FileIO' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     24\u001b[0m     log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m---> 25\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraintest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmixed_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmixed_precision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#accumulate_loss=2,\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;66;43;03m#loss_handler_type='dict', \u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mschedulers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedulers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     log[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_loss\n\u001b[0;32m     30\u001b[0m     tp \u001b[38;5;241m=\u001b[39m fp \u001b[38;5;241m=\u001b[39m fn \u001b[38;5;241m=\u001b[39m rtp \u001b[38;5;241m=\u001b[39m rfp \u001b[38;5;241m=\u001b[39m rfn \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32md:\\diploma\\cv-corruption-research\\dlutils\\learn\\traintest.py:98\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer, model_input_keys, gt_keys, accumulate_loss, schedulers, pbar, mixed_precision, device)\u001b[0m\n\u001b[0;32m     94\u001b[0m handler \u001b[38;5;241m=\u001b[39m partial(batch_handler, model\u001b[38;5;241m=\u001b[39mmodel, loss_fn\u001b[38;5;241m=\u001b[39mloss_fn, model_input_keys\u001b[38;5;241m=\u001b[39mmodel_input_keys,\n\u001b[0;32m     95\u001b[0m                   gt_keys\u001b[38;5;241m=\u001b[39mgt_keys, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     96\u001b[0m pbar \u001b[38;5;241m=\u001b[39m globaldefs\u001b[38;5;241m.\u001b[39mget_tqdm(pbar)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_iter, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     99\u001b[0m     total_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    100\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32md:\\diploma\\cv-corruption-research\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\diploma\\cv-corruption-research\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\diploma\\cv-corruption-research\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle '_io.FileIO' object"
     ]
    }
   ],
   "source": [
    "benchmark_root = 'samples_benchmarks/'\n",
    "benchmark_files =['026','035','045']\n",
    "#ru_benchmarks = ['Mytishi', 'Ufa', 'Kolomna']\n",
    "\n",
    "benchmarks = [NpFileReader(os.path.join(benchmark_root, f)+'/img_mask.np') for f in benchmark_files]\n",
    "\n",
    "max_f1, max_rt = 0, 0\n",
    "\n",
    "# cut some references for HistogramMatching\n",
    "reference_sample_size=1024\n",
    "reference = (benchmarks[0][:3, 3800:3800+reference_sample_size, 3400:3400+reference_sample_size].transpose(1, 2, 0),\n",
    "             benchmarks[1][:3, :reference_sample_size, :reference_sample_size].transpose(1, 2, 0),\n",
    "             benchmarks[2][:3, 2048:2048+reference_sample_size, 2048:2048+reference_sample_size].transpose(1, 2, 0)\n",
    "            #,  benchmarks[3][:3, :reference_sample_size, :reference_sample_size].transpose(1, 2, 0),\n",
    "            #  benchmarks[4][:3, :reference_sample_size, :reference_sample_size].transpose(1, 2, 0),\n",
    "            #  benchmarks[5][:3, 1024:1024+reference_sample_size, 1024:1024+reference_sample_size].transpose(1, 2, 0),\n",
    "            #  benchmarks[6][:3, 1024:1024+reference_sample_size, 1024:1024+reference_sample_size].transpose(1, 2, 0),\n",
    "             )\n",
    "\n",
    "benchmarks_weights = np.array([np.sum(b.shape[1:]) for b in benchmarks])\n",
    "benchmarks_weights = benchmarks_weights / np.max(benchmarks_weights)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    log = dict()\n",
    "    train_loss = traintest.train(train_loader, model, loss_fn, \n",
    "                                 optimizer, mixed_precision=mixed_precision, #accumulate_loss=2,\n",
    "                                 #loss_handler_type='dict', \n",
    "                                 schedulers=schedulers, pbar=pbar, device=device)\n",
    "    log['Train'] = train_loss\n",
    "            \n",
    "    tp = fp = fn = rtp = rfp = rfn = 0\n",
    "    rt_ru = []\n",
    "    sw_ru = []\n",
    "    sh_ru = []\n",
    "    wl_ru = []\n",
    "            \n",
    "    for b_name, b in zip(benchmark_files, benchmarks):\n",
    "        rgb = b[:3]\n",
    "        gt = postprocessors.separate_instances(b[3][0], 3, 4)\n",
    "        pred = predict.predict(model, rgb, preprocess=val_preprocess, sample_size=1024,\n",
    "                               postprocess=val_postprocess, device=device)[0]  \n",
    "    \n",
    "                \n",
    "        pred = postprocessors.separate_instances(pred, 3, 4)\n",
    "                \n",
    "        scores = metrics.get_iou_multiclass(pred, gt, n_classes=4)\n",
    "        for sc, cn in zip(scores[1:], ('sh', 'wl', 'rt')):\n",
    "            log[f'{b_name}_{cn}'] = sc\n",
    "                    \n",
    "        _tp, _fp, _fn = metrics.objectwise_stats_raster((pred==3).astype(np.uint8), (gt==3).astype(np.uint8))\n",
    "        tp += _tp\n",
    "        fp += _fp\n",
    "        fn += _fn\n",
    "        log[f'{b_name}_prec'] = metrics.precision(_tp, _fp)\n",
    "        log[f'{b_name}_rec'] = metrics.recall(_tp, _fn)\n",
    "        log[f'{b_name}_f1'] = metrics.f1_score(log[f'{b_name}_prec'], log[f'{b_name}_rec'])\n",
    "        \n",
    "        #if b_name in ru_benchmarks:\n",
    "        rtp += _tp\n",
    "        rfp += _fp\n",
    "        rfn += _fn\n",
    "        rt_ru.append(scores[3])\n",
    "        sh_ru.append(scores[1])\n",
    "        wl_ru.append(scores[2])\n",
    "        sw_ru.append((scores[1] + scores[2]) / 2)\n",
    "                        \n",
    "    log['Avg_prec'] = metrics.precision(tp, fp)\n",
    "    log['Avg_rec'] = metrics.recall(tp, fn)\n",
    "    log['Avg_f1'] = metrics.f1_score(log['Avg_prec'], log['Avg_rec'])\n",
    "            \n",
    "    log['Avg_prec_ru'] = metrics.precision(rtp, rfp)\n",
    "    log['Avg_rec_ru'] = metrics.recall(rtp, rfn)\n",
    "    log['Avg_f1_ru'] = metrics.f1_score(log['Avg_prec_ru'], log['Avg_rec_ru'])\n",
    "            \n",
    "    log['Avg_rt_ru'] = float(np.average(rt_ru, weights=benchmarks_weights[:3]))\n",
    "    log['Avg_sw_ru'] = float(np.average(sw_ru, weights=benchmarks_weights[:3]))\n",
    "    log['Avg_sh_ru'] = float(np.average(sh_ru, weights=benchmarks_weights[:3]))\n",
    "    log['Avg_wl_ru'] = float(np.average(wl_ru, weights=benchmarks_weights[:3]))\n",
    "            \n",
    "    log['Avg_sw'] = metrics.avg_class_score(log, ('sh','wl'), weights=benchmarks_weights)\n",
    "    log['Avg_rt'] = metrics.avg_class_score(log, ('rt',), weights=benchmarks_weights)\n",
    "\n",
    "    # if log['Avg_f1_ru'] > max_f1 or log['Avg_rt_ru'] > max_rt:\n",
    "    #    torch.save(model.module.state_dict(),\n",
    "    #               f\"unet_resnet34/Unet_{np.round(log['Avg_f1_ru'], 3)}_{np.round(log['Avg_rt_ru'], 3)}_{np.round(log['Avg_sw_ru'], 3)}.pth\")\n",
    "\n",
    "    wandb.log(log)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90651b2f-3678-4011-bccb-c9d102c972c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.module.state_dict(), f\"unet_resnet34/Unet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99e61c7b-b7c2-46d2-a567-b178cf876b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fa31202-2a5d-4f6a-889f-b8890ece26b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9446290-e732-4edd-b5f0-cd7d530a3a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakharov/miniconda3/envs/torchaero/lib/python3.10/site-packages/segmentation_models_pytorch/base/model.py:16: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if h % output_stride != 0 or w % output_stride != 0:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 1024])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms as T\n",
    "\n",
    "model = smp.Unet(encoder_name='mit_b3', encoder_weights = None, classes=5, activation=None)\n",
    "model.load_state_dict(torch.load('models/Unet_0.7052_0.8498_0.7048.pth'))\n",
    "\n",
    "class ModelTrace(torch.nn.Module):\n",
    "    def __init__(self, model, transform, inv_transform, device):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.model.to(device)\n",
    "        self.transform = transform\n",
    "        self.inv_transform = inv_transform\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        x = self.transform(x.to(torch.float))\n",
    "        x = self.model(x)\n",
    "        x = self.inv_transform(x)\n",
    "        return x\n",
    "\n",
    "normparams = {'mean': (106.9, 108.9, 98.4), 'std': (54.6, 51.0, 50.5)}\n",
    "tr = T.Normalize(**normparams)\n",
    "inv_tr = lambda x: (torch.max(x, dim=1, keepdim=False)[1]).to(torch.uint8)\n",
    "trace = ModelTrace(model, tr, inv_tr, 'cpu')\n",
    "model_tr = torch.jit.trace(trace, torch.rand(1, 3, 1024, 1024))\n",
    "model_tr(torch.rand(1, 3, 1024, 1024)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1da2a703-1279-451c-ae1e-3bbc37c57a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tr.save('models/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55af4da6-ab19-4264-ae23-d19335e8e60b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_io.FileIO' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\diploma\\cv-corruption-research\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\diploma\\cv-corruption-research\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\diploma\\cv-corruption-research\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle '_io.FileIO' object"
     ]
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d7f4f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mask': tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]]]),\n",
       " 'image': tensor([[[[-5.8451e-01,  1.0764e-03,  3.6707e-01,  ...,  3.7675e-02,\n",
       "            -2.0022e-01,  2.7557e-01],\n",
       "           [-1.6276e+00, -1.5178e+00, -1.2433e+00,  ...,  2.3897e-01,\n",
       "            -6.2111e-01, -8.7730e-01],\n",
       "           [-1.7923e+00, -1.5727e+00, -1.5178e+00,  ...,  3.1217e-01,\n",
       "            -5.8451e-01, -9.1390e-01],\n",
       "           ...,\n",
       "           [-5.3822e-02, -3.8321e-01, -1.7191e+00,  ..., -4.0151e-01,\n",
       "            -1.0054e+00,  9.2574e-02],\n",
       "           [ 2.2153e+00,  1.7395e+00,  1.8127e+00,  ...,  1.4747e-01,\n",
       "             5.5006e-01,  1.6846e+00],\n",
       "           [ 2.1055e+00, -1.9021e+00,  1.6114e+00,  ...,  5.5006e-01,\n",
       "             1.1722e+00,  1.9774e+00]],\n",
       " \n",
       "          [[-6.0574e-01,  6.0253e-02,  3.1490e-01,  ...,  9.9429e-02,\n",
       "            -1.5521e-01,  4.1284e-01],\n",
       "           [-1.7614e+00, -1.7027e+00, -1.3697e+00,  ...,  2.1696e-01,\n",
       "            -6.8409e-01, -9.1914e-01],\n",
       "           [-1.8594e+00, -1.6831e+00, -1.6439e+00,  ...,  3.3448e-01,\n",
       "            -5.2738e-01, -9.1914e-01],\n",
       "           ...,\n",
       "           [ 2.5613e-01, -1.5521e-01, -1.4872e+00,  ..., -2.3357e-01,\n",
       "            -8.6038e-01,  2.7572e-01],\n",
       "           [ 2.6459e+00,  2.0778e+00,  2.2737e+00,  ...,  3.7366e-01,\n",
       "             7.6542e-01,  2.0386e+00],\n",
       "           [ 2.4696e+00, -2.0748e+00,  1.9407e+00,  ...,  7.6542e-01,\n",
       "             1.4314e+00,  2.3325e+00]],\n",
       " \n",
       "          [[-6.8182e-01, -8.7521e-02,  1.5020e-01,  ..., -1.4695e-01,\n",
       "            -3.2524e-01,  7.0959e-02],\n",
       "           [-1.8110e+00, -1.6525e+00, -1.3950e+00,  ..., -8.2809e-03,\n",
       "            -8.4030e-01, -1.3950e+00],\n",
       "           [-1.7516e+00, -1.6525e+00, -1.5931e+00,  ...,  1.1058e-01,\n",
       "            -8.6011e-01, -1.3554e+00],\n",
       "           ...,\n",
       "           [-8.7521e-02, -4.8372e-01, -1.9100e+00,  ..., -4.6391e-01,\n",
       "            -1.0978e+00,  7.0959e-02],\n",
       "           [ 2.4878e+00,  1.7944e+00,  1.9727e+00,  ...,  1.1529e-02,\n",
       "             5.6621e-01,  1.7944e+00],\n",
       "           [ 2.3293e+00, -1.8902e+00,  1.7548e+00,  ...,  5.6621e-01,\n",
       "             1.2199e+00,  2.1312e+00]]]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0,[0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec018d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
