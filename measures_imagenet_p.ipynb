{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as trn\n",
    "import torchvision.transforms.functional as trn_F\n",
    "import torchvision.models as models\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "# from resnext_50_32x4d import resnext_50_32x4d\n",
    "# from resnext_101_32x4d import resnext_101_32x4d\n",
    "# from resnext_101_64x4d import resnext_101_64x4d\n",
    "from scipy.stats import rankdata\n",
    "from dataloaders import FullDataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [--model-name {alexnet,squeezenet1.1,vgg11,vgg19,vggbn,densenet121,densenet169,densenet201,densenet161,resnet18,resnet34,resnet50,resnet101,resnet152,resnext50,resnext101,resnext101_64}]\n",
      "                             [--perturbation {gaussian_noise,shot_noise,motion_blur,zoom_blur,spatter,brightness,translate,rotate,tilt,scale,speckle_noise,gaussian_blur,snow,shear}]\n",
      "                             [--difficulty {1,2,3}] [--ngpu NGPU]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9018 --control=9016 --hb=9015 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"591ce152-6629-4602-b169-7b1029663fb3\" --shell=9017 --transport=\"tcp\" --iopub=9019 --f=c:\\Users\\Darya\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-2860geRq40NExwUA.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\diploma\\cv-corruption-research\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser.add_argument('--model-name', '-m', default='resnet18', type=str,\n",
    "                    choices=['alexnet', 'squeezenet1.1', 'vgg11', 'vgg19', 'vggbn',\n",
    "                             'densenet121', 'densenet169', 'densenet201', 'densenet161',\n",
    "                             'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152',\n",
    "                             'resnext50', 'resnext101', 'resnext101_64'])\n",
    "parser.add_argument('--perturbation', '-p', default='brightness', type=str,\n",
    "                    choices=['gaussian_noise', 'shot_noise', 'motion_blur', 'zoom_blur',\n",
    "                             'spatter', 'brightness', 'translate', 'rotate', 'tilt', 'scale',\n",
    "                             'speckle_noise', 'gaussian_blur', 'snow', 'shear'])\n",
    "parser.add_argument('--difficulty', '-d', type=int, default=1, choices=[1, 2, 3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model_name == 'alexnet':\n",
    "    net = models.AlexNet()\n",
    "    net.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "                                           # model_dir='/share/data/lang/users/dan/.torch/models'))\n",
    "                                           model_dir='/share/data/vision-greg2/pytorch_models/alexnet'))\n",
    "    args.test_bs = 6\n",
    "\n",
    "elif args.model_name == 'squeezenet1.0':\n",
    "    net = models.SqueezeNet(version=1.0)\n",
    "    net.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
    "                                           # model_dir='/share/data/lang/users/dan/.torch/models'))\n",
    "                                           model_dir='/share/data/vision-greg2/pytorch_models/squeezenet'))\n",
    "    args.test_bs = 6\n",
    "\n",
    "elif args.model_name == 'squeezenet1.1':\n",
    "    net = models.SqueezeNet(version=1.1)\n",
    "    net.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
    "                                           # model_dir='/share/data/lang/users/dan/.torch/models'))\n",
    "                                           model_dir='/share/data/vision-greg2/pytorch_models/squeezenet'))\n",
    "    args.test_bs = 6\n",
    "\n",
    "elif 'vgg' in args.model_name:\n",
    "    if 'bn' not in args.model_name and '11' not in args.model_name:\n",
    "        net = models.vgg19()\n",
    "        net.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "                                               # model_dir='/share/data/lang/users/dan/.torch/models'))\n",
    "                                               model_dir='/share/data/vision-greg2/pytorch_models/vgg'))\n",
    "    elif '11' in args.model_name:\n",
    "        net = models.vgg11()\n",
    "        net.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "                                               # model_dir='/share/data/lang/users/dan/.torch/models'))\n",
    "                                               model_dir='/share/data/vision-greg2/pytorch_models/vgg'))\n",
    "    else:\n",
    "        net = models.vgg19_bn()\n",
    "        net.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "                                               # model_dir='/share/data/lang/users/dan/.torch/models'))\n",
    "                                               model_dir='/share/data/vision-greg2/pytorch_models/vgg'))\n",
    "    args.test_bs = 2\n",
    "\n",
    "elif args.model_name == 'densenet121':\n",
    "    net = models.densenet121()\n",
    "\n",
    "    import re\n",
    "    # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
    "    # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
    "    # They are also in the checkpoints in model_urls.\n",
    "    # This pattern is used to find such keys.\n",
    "    pattern = re.compile(\n",
    "        r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
    "    state_dict = model_zoo.load_url('https://download.pytorch.org/models/densenet121-a639ec97.pth',\n",
    "                                    model_dir='/share/data/vision-greg2/pytorch_models/densenet')\n",
    "    for key in list(state_dict.keys()):\n",
    "        res = pattern.match(key)\n",
    "        if res:\n",
    "            new_key = res.group(1) + res.group(2)\n",
    "            state_dict[new_key] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "\n",
    "    net.load_state_dict(state_dict)\n",
    "    args.test_bs = 5\n",
    "\n",
    "elif args.model_name == 'densenet161':\n",
    "    net = models.densenet161()\n",
    "\n",
    "    import re\n",
    "    pattern = re.compile(\n",
    "        r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
    "    state_dict = model_zoo.load_url('https://download.pytorch.org/models/densenet161-8d451a50.pth',\n",
    "                                    model_dir='/share/data/vision-greg2/pytorch_models/densenet')\n",
    "    for key in list(state_dict.keys()):\n",
    "        res = pattern.match(key)\n",
    "        if res:\n",
    "            new_key = res.group(1) + res.group(2)\n",
    "            state_dict[new_key] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "    args.test_bs = 3\n",
    "\n",
    "elif args.model_name == 'resnet18':\n",
    "    net = models.resnet18()\n",
    "    net.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "                                           # model_dir='/share/data/lang/users/dan/.torch/models'))\n",
    "                                           model_dir='/share/data/vision-greg2/pytorch_models/resnet'))\n",
    "    args.test_bs = 5\n",
    "\n",
    "elif args.model_name == 'resnet34':\n",
    "    net = models.resnet34()\n",
    "    net.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "                                           # model_dir='/share/data/lang/users/dan/.torch/models'))\n",
    "                                           model_dir='/share/data/vision-greg2/pytorch_models/resnet'))\n",
    "    args.test_bs = 4\n",
    "\n",
    "elif args.model_name == 'resnet50':\n",
    "    net = models.resnet50()\n",
    "    net.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "                                           # model_dir='/share/data/lang/users/dan/.torch/models'))\n",
    "                                           model_dir='/share/data/vision-greg2/pytorch_models/resnet'))\n",
    "    args.test_bs = 4\n",
    "\n",
    "elif args.model_name == 'resnet101':\n",
    "    net = models.resnet101()\n",
    "    net.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "                                           # model_dir='/share/data/lang/users/dan/.torch/models'))\n",
    "                                           model_dir='/share/data/vision-greg2/pytorch_models/resnet'))\n",
    "    args.test_bs = 3\n",
    "\n",
    "elif args.model_name == 'resnet152':\n",
    "    net = models.resnet152()\n",
    "    net.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "                                           # model_dir='/share/data/lang/users/dan/.torch/models'))\n",
    "                                           model_dir='/share/data/vision-greg2/pytorch_models/resnet'))\n",
    "    args.test_bs = 3\n",
    "\n",
    "elif args.model_name == 'resnext50':\n",
    "    net = resnext_50_32x4d\n",
    "    # net.load_state_dict(torch.load('/share/data/lang/users/dan/.torch/models/resnext_50_32x4d.pth'))\n",
    "    net.load_state_dict(torch.load('/share/data/vision-greg2/pytorch_models/resnext_50_32x4d.pth'))\n",
    "    args.test_bs = 3\n",
    "\n",
    "elif args.model_name == 'resnext101':\n",
    "    net = resnext_101_32x4d\n",
    "    # net.load_state_dict(torch.load('/share/data/lang/users/dan/.torch/models/resnext_101_32x4d.pth'))\n",
    "    net.load_state_dict(torch.load('/share/data/vision-greg2/pytorch_models/resnext_101_32x4d.pth'))\n",
    "    args.test_bs = 3\n",
    "\n",
    "elif args.model_name == 'resnext101_64':\n",
    "    net = resnext_101_64x4d\n",
    "    # net.load_state_dict(torch.load('/share/data/lang/users/dan/.torch/models/resnext_101_64x4d.pth'))\n",
    "    net.load_state_dict(torch.load('/share/data/vision-greg2/pytorch_models/resnext_101_64x4d.pth'))\n",
    "    args.test_bs = 3\n",
    "\n",
    "args.prefetch = 4\n",
    "\n",
    "if args.ngpu > 1:\n",
    "    net = torch.nn.DataParallel(net, device_ids=list(range(args.ngpu)))\n",
    "\n",
    "if args.ngpu > 0:\n",
    "    net.cuda()\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "if args.ngpu > 0:\n",
    "    torch.cuda.manual_seed(1)\n",
    "\n",
    "net.eval()\n",
    "cudnn.benchmark = True  # fire on all cylinders\n",
    "\n",
    "print('Model Loaded\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /hendrycs_models/resnet18\\resnet18-5c106cde.pth\n",
      "100%|██████████| 44.7M/44.7M [00:04<00:00, 11.6MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elif args.model_name == 'resnet18':\n",
    "\n",
    "model_name = 'resnet18'\n",
    "net = models.resnet18()\n",
    "net.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "                                        # model_dir='/share/data/lang/users/dan/.torch/models'))\n",
    "                                        model_dir='/hendrycs_models/resnet18'))\n",
    "test_bs = 5\n",
    "\n",
    "prefetch = 4\n",
    "\n",
    "net.eval()\n",
    "cudnn.benchmark = True\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "perturbation = 'adjust_contrast'\n",
    "difficulty = 0.8\n",
    "\n",
    "dataset_folder = \"/distorted_images/\" + perturbation + '_' + str(difficulty)\n",
    "# try:\n",
    "#     original_umask = os.umask(0)\n",
    "#     os.makedirs(dataset_folder, mode = 0o777)\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "loader = torch.utils.data.DataLoader(FullDataset(dataset_folder, transform=trn.Compose([trn.ToTensor(), trn.Normalize(mean, std)])))\n",
    "\n",
    "print('Data Loaded\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dataloaders.FullDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(FullDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = np.asarray(range(1, 1001))\n",
    "cum_sum_top5 = np.cumsum(np.asarray([0] + [1] * 5 + [0] * (999 - 5)))\n",
    "recip = 1./identity\n",
    "\n",
    "# def top5_dist(sigma):\n",
    "#     result = 0\n",
    "#     for i in range(1,6):\n",
    "#         for j in range(min(sigma[i-1], i) + 1, max(sigma[i-1], i) + 1):\n",
    "#             if 1 <= j - 1 <= 5:\n",
    "#                 result += 1\n",
    "#     return result\n",
    "\n",
    "def dist(sigma, mode='top5'):\n",
    "    if mode == 'top5':\n",
    "        return np.sum(np.abs(cum_sum_top5[:5] - cum_sum_top5[sigma-1][:5]))\n",
    "    elif mode == 'zipf':\n",
    "        return np.sum(np.abs(recip - recip[sigma-1])*recip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_dist(ranks, noise_perturbation=True if 'noise' in perturbation else False, mode='top5'):\n",
    "    result = 0\n",
    "    step_size = 1 #if noise_perturbation else args.difficulty\n",
    "\n",
    "    for vid_ranks in ranks:\n",
    "        result_for_vid = []\n",
    "\n",
    "        for i in range(step_size):\n",
    "            perm1 = vid_ranks[i]\n",
    "            perm1_inv = np.argsort(perm1)\n",
    "\n",
    "            for rank in vid_ranks[i::step_size][1:]:\n",
    "                perm2 = rank\n",
    "                result_for_vid.append(dist(perm2[perm1_inv], mode))\n",
    "                if not noise_perturbation:\n",
    "                    perm1 = perm2\n",
    "                    perm1_inv = np.argsort(perm1)\n",
    "\n",
    "        result += np.mean(result_for_vid) / len(ranks)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_prob(predictions, noise_perturbation=True if 'noise' in perturbation else False):\n",
    "    result = 0\n",
    "    step_size = 1 #if noise_perturbation else args.difficulty\n",
    "\n",
    "    for vid_preds in predictions:\n",
    "        result_for_vid = []\n",
    "\n",
    "        for i in range(step_size):\n",
    "            prev_pred = vid_preds[i]\n",
    "\n",
    "            for pred in vid_preds[i::step_size][1:]:\n",
    "                result_for_vid.append(int(prev_pred != pred))\n",
    "                if not noise_perturbation: prev_pred = pred\n",
    "\n",
    "        result += np.mean(result_for_vid) / len(predictions)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Metrics\n",
      "\n",
      "Flipping Prob\t0.00000\n",
      "Top5 Distance\t0.00000\n",
      "Zipf Distance\t0.00000\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predictions, ranks = [], []\n",
    "with torch.no_grad():\n",
    "\n",
    "    for data, target in loader:\n",
    "        num_vids = data.size(0)\n",
    "        data = data.view(-1,3,224,224).cuda()\n",
    "\n",
    "        output = net(data)\n",
    "\n",
    "        for vid in output.view(num_vids, -1, 1000):\n",
    "            predictions.append(vid.argmax(1).to('cpu').numpy())\n",
    "            ranks.append([np.uint16(rankdata(-frame, method='ordinal')) for frame in vid.to('cpu').numpy()])\n",
    "\n",
    "\n",
    "ranks = np.asarray(ranks)\n",
    "\n",
    "print('Computing Metrics\\n')\n",
    "\n",
    "print('Flipping Prob\\t{:.5f}'.format(flip_prob(predictions)))\n",
    "print('Top5 Distance\\t{:.5f}'.format(ranking_dist(ranks, mode='top5')))\n",
    "print('Zipf Distance\\t{:.5f}'.format(ranking_dist(ranks, mode='zipf')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
